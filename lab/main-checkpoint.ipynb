{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5cddc7-e521-4cbf-89cd-3b42bd298962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 14:57:11.542306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLPClassifier\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/distribute/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/keras/distribute/sidecar_evaluator.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Python module for evaluation loop.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os, re, time, math, tqdm, itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def scatterplot(network_data):\n",
    "    pyo.init_notebook_mode(connected=True)\n",
    "    fig = px.scatter(x=network_data[\"Flow Bytes/s\"][:100000],\n",
    "                     y=network_data[\"Avg Bwd Segment Size\"][:100000])\n",
    "    fig.show()\n",
    "\n",
    "def plot_number(network_data):\n",
    "    sns.set(rc={'figure.figsize': (12, 6)})\n",
    "    plt.xlabel('Attack Type')\n",
    "    sns.set_theme()\n",
    "    ax = sns.countplot(x='Label', data=network_data)\n",
    "    ax.set(xlabel='Attack Type', ylabel='Number of Attacks')\n",
    "    plt.show()\n",
    "\n",
    "def loading_data(path):\n",
    "    \"\"\"\n",
    "      https://stackoverflow.com/questions/45529507/unicodedecodeerror-utf-8-codec-cant-decode-byte-0x96-in-position-35-invalid\n",
    "    \"\"\"\n",
    "    return pd.read_csv(path, encoding='cp1252')\n",
    "\n",
    "def validate(network_data):\n",
    "    \"\"\"\n",
    "        ptr\n",
    "    \"\"\"\n",
    "    try:\n",
    "        network_data['Label']\n",
    "    except KeyError:\n",
    "        columns = [sanitize(i) for i in network_data.columns]\n",
    "        network_data.columns = columns\n",
    "\n",
    "def sanitize(column):\n",
    "    \"\"\"\n",
    "        de-recursion\n",
    "    \"\"\"\n",
    "    while ' ' == column[0]:\n",
    "        column = column[1:]\n",
    "    return column\n",
    "\n",
    "def plot_number(network_data):\n",
    "    sns.set(rc={'figure.figsize': (12, 6)})\n",
    "    plt.xlabel('Attack Type')\n",
    "    sns.set_theme()\n",
    "    ax = sns.countplot(x='Label', data=network_data)\n",
    "    ax.set(xlabel='Attack Type', ylabel='Number of Attacks')\n",
    "    plt.show()\n",
    "\n",
    "def circle(network_data):\n",
    "    cleaned_data = network_data.dropna()\n",
    "    cleaned_data.isna().sum().to_numpy()\n",
    "    label_encoder = LabelEncoder()\n",
    "    cleaned_data['Label']= label_encoder.fit_transform(cleaned_data['Label'])\n",
    "    cleaned_data['Label'].unique()\n",
    "    cleaned_data['Label'].value_counts()\n",
    "    data_1 = cleaned_data[cleaned_data['Label'] == 0]\n",
    "    data_2 = cleaned_data[cleaned_data['Label'] == 1]\n",
    "    data_3 = cleaned_data[cleaned_data['Label'] == 2]\n",
    "\n",
    "    # make benign feature\n",
    "    y_1 = np.zeros(data_1.shape[0])\n",
    "    y_benign = pd.DataFrame(y_1)\n",
    "\n",
    "    # make bruteforce feature\n",
    "    y_2 = np.ones(data_2.shape[0])\n",
    "    y_bf = pd.DataFrame(y_2)\n",
    "\n",
    "    # make bruteforceSSH feature\n",
    "    y_3 = np.full(data_3.shape[0], 2)\n",
    "    y_ssh = pd.DataFrame(y_3)\n",
    "\n",
    "    # merging the original dataframe\n",
    "    X = pd.concat([data_1, data_2, data_3], sort=True)\n",
    "    y = pd.concat([y_benign, y_bf, y_ssh], sort=True)\n",
    "    data_1_resample = resample(data_1, n_samples=20000, \n",
    "                           random_state=123, replace=True)\n",
    "    data_2_resample = resample(data_2, n_samples=20000, \n",
    "                            random_state=123, replace=True)\n",
    "    data_3_resample = resample(data_3, n_samples=20000, \n",
    "                            random_state=123, replace=True)\n",
    "    train_dataset = pd.concat([data_1_resample, data_2_resample, data_3_resample])\n",
    "    train_dataset.head(2)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    circle = plt.Circle((0, 0), 0.7, color='white')\n",
    "    plt.title('Intrusion Attack Type Distribution')\n",
    "    plt.pie(train_dataset['Label'].value_counts(), labels=['Benign', 'BF', 'BF-SSH'], colors=['blue', 'magenta', 'cyan'])\n",
    "    p = plt.gcf()\n",
    "    p.gca().add_artist(circle)\n",
    "\n",
    "\n",
    "    test_dataset = train_dataset.sample(frac=0.1)\n",
    "    target_train = train_dataset['Label']\n",
    "    target_test = test_dataset['Label']\n",
    "    target_train.unique(), target_test.unique()\n",
    "\n",
    "    y_train = to_categorical(target_train, num_classes=3)\n",
    "    y_test = to_categorical(target_test, num_classes=3)\n",
    "\n",
    "    train_dataset = train_dataset.drop(columns = [\"Timestamp\", \"Protocol\",\"PSH Flag Cnt\",\"Init Fwd Win Byts\",\"Flow Byts/s\",\"Flow Pkts/s\", \"Label\"], axis=1)\n",
    "    test_dataset = test_dataset.drop(columns = [\"Timestamp\", \"Protocol\",\"PSH Flag Cnt\",\"Init Fwd Win Byts\",\"Flow Byts/s\",\"Flow Pkts/s\", \"Label\"], axis=1)\n",
    "\n",
    "    X_train = train_dataset.iloc[:, :-1].values\n",
    "    X_test = test_dataset.iloc[:, :-1].values\n",
    "    X_test.show()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # reshape the data for CNN\n",
    "    X_train = X_train.reshape(len(X_train), X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(len(X_test), X_test.shape[1], 1)\n",
    "    X_train.shape, X_test.shape\n",
    "    \n",
    "\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(72, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # adding a pooling layer\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(72, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
    "                    padding='same', input_shape=(72, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def main(path):\n",
    "    network_data = loading_data(path)\n",
    "    validate(network_data)\n",
    "\n",
    "    print(network_data.shape)\n",
    "    print(network_data.info())\n",
    "    print(network_data['Label'].value_counts())\n",
    "\n",
    "    # plot_number(network_data)\n",
    "    # scatterplot(network_data)\n",
    "    # circle(network_data)\n",
    "    model = model()\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = \"/Users/TrungLT/CNN/Input/\"\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        main(path)\n",
    "    elif os.path.isdir(path):\n",
    "        for dirname, _, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                file = os.path.join(dirname, filename)\n",
    "                print(f\"We will show chart from {file}\")\n",
    "                try:\n",
    "                    main(file)\n",
    "                except Exception as err:\n",
    "                    print(err)\n",
    "                print(\"---ENDING---\")\n",
    "    else:\n",
    "        print(\"The path is not file or directory\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481f3e9-89c2-40fc-8758-d0b9c8f9d578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1d936-1f90-48e2-8f91-fb8e3ff72878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
